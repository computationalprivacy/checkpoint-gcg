# Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses
This repository contains the source code for the paper "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses" by Xiaoxue Yang*, Bozhidar Stevanoski*, Matthieu Meeus, and Yves-Alexandre de Montjoye (* denotes equal contribution).
